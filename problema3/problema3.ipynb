{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Algoritmo de Expectation-Maximization (EM) para GMM**\n",
    "\n",
    "El algoritmo de Expectation-Maximization (EM) nos permite encontrar un máximo de la verosimilitud de los datos $X$, con respecto a los parámetros $\\theta = \\{ \\pi_j, \\mu_j, \\Sigma_j \\}$ de un modelo de mezcla gaussiana (GMM).\n",
    "\n",
    "**Paso E (Expectation step)**\n",
    "En el paso E, calculamos la expectativa de la función de verosimilitud completa con respecto a la distribución posterior de la variable latente $Z$, dadas las observaciones actuales de los datos y los parámetros actuales $\\theta^{(t)}$.\n",
    "\n",
    "La función de verosimilitud completa es:\n",
    "\n",
    "$ p(X, Z | \\theta) = \\prod_{i=1}^{N} \\prod_{j=1}^{K} \\left[ \\pi_j \\mathcal{N}(x_i | \\mu_j, \\Sigma_j) \\right]^{z_{ij}} $\n",
    "\n",
    "La expectativa a calcular es:\n",
    "\n",
    "$ Q(\\theta, \\theta^{(t)}) = \\mathbb{E}_{Z | X, \\theta^{(t)}} \\left[ \\log p(X, Z | \\theta) \\right] $\n",
    "\n",
    "Esto se traduce en:\n",
    "\n",
    "$ Q(\\theta, \\theta^{(t)}) = \\sum_{i=1}^{N} \\sum_{j=1}^{K} \\gamma_{ij}^{(t)} \\left[ \\log \\pi_j + \\log \\mathcal{N}(x_i | \\mu_j, \\Sigma_j) \\right] $\n",
    "\n",
    "donde $\\gamma_{ij}^{(t)}$ es la probabilidad a posteriori de que $x_i$ pertenezca a la $j$-ésima componente, calculada como:\n",
    "\n",
    "$ \\gamma_{ij}^{(t)} = \\frac{\\pi_j^{(t)} \\mathcal{N}(x_i | \\mu_j^{(t)}, \\Sigma_j^{(t)})}{\\sum_{l=1}^{K} \\pi_l^{(t)} \\mathcal{N}(x_i | \\mu_l^{(t)}, \\Sigma_l^{(t)})} $\n",
    "\n",
    "**Paso M (Maximization step)**\n",
    "En el paso M, maximizamos $Q(\\theta, \\theta^{(t)})$ con respecto a los parámetros $\\theta$ para obtener los nuevos valores de los parámetros $\\theta^{(t+1)}$.\n",
    "\n",
    "Los nuevos parámetros se obtienen resolviendo las siguientes ecuaciones:\n",
    "\n",
    "$ \\pi_j^{(t+1)} = \\frac{1}{N} \\sum_{i=1}^{N} \\gamma_{ij}^{(t)} $\n",
    "\n",
    "$ \\mu_j^{(t+1)} = \\frac{\\sum_{i=1}^{N} \\gamma_{ij}^{(t)} x_i}{\\sum_{i=1}^{N} \\gamma_{ij}^{(t)}} $\n",
    "\n",
    "$ \\Sigma_j^{(t+1)} = \\frac{\\sum_{i=1}^{N} \\gamma_{ij}^{(t)} (x_i - \\mu_j^{(t+1)})(x_i - \\mu_j^{(t+1)})^T}{\\sum_{i=1}^{N} \\gamma_{ij}^{(t)}} $\n",
    "\n",
    "**Resumen del Algoritmo EM para GMM**\n",
    "\n",
    "**Inicialización:** Elegir valores iniciales para los parámetros $\\pi_j^{(0)}, \\mu_j^{(0)}, \\Sigma_j^{(0)}$.\\\\\n",
    "\n",
    "**Paso E:** Calcular $\\gamma_{ij}^{(t)}$ para cada $i$ y $j$.\\\\\n",
    "\n",
    "**Paso M:** Actualizar los parámetros $\\pi_j^{(t+1)}, \\mu_j^{(t+1)}, \\Sigma_j^{(t+1)}$.\\\\\n",
    "\n",
    "**Convergencia:** Repetir los pasos E y M hasta la convergencia de los parámetros.\\\\\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
